{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "For this project, we want to solve the question, “Given a certain temperature and absolute magnitude, what type of star do we have?” This is a classification problem, specifically for determining star type, whether a star is a Red Dwarf, Brown Dwarf, White Dwarf, Main Sequence, Super Giant or Hyper Giant according to the temperature and the absolute magnitude. Absolute magnitude (M) is a measure of the luminosity of a celestial object: it measures the star’s luminosity at a distance of 32.6 light years, ensuring the measurements are all standard and relative to each other. The energy inside a star increases from Red Dwarf to Hyper Giants. Therefore, each type of star has its own specific properties including a temperature range and a range of absolute magnitude. We want to look at how we can use these two star properties to predict what type a star could be. We will be using a dataset from Kaggle called “Star Type Classification / NASA”. There are 240 observations in the dataset, 4 quantitative variables (Temperature, Luminosity, Solar Radius, Absolute Magnitude) and 3 qualitative variables (Color, Spectral Class, Type), we will choose temperature and absolute magnitude as our variables to predict star type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.3     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "Warning message:\n",
      "“package ‘ggplot2’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘tibble’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘tidyr’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘dplyr’ was built under R version 4.0.2”\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "Warning message:\n",
      "“package ‘tidymodels’ was built under R version 4.0.2”\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 0.1.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom    \u001b[39m 0.7.0      \u001b[32m✔\u001b[39m \u001b[34mrecipes  \u001b[39m 0.1.13\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials    \u001b[39m 0.0.9      \u001b[32m✔\u001b[39m \u001b[34mrsample  \u001b[39m 0.0.7 \n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer    \u001b[39m 0.5.4      \u001b[32m✔\u001b[39m \u001b[34mtune     \u001b[39m 0.1.1 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata\u001b[39m 0.0.2      \u001b[32m✔\u001b[39m \u001b[34mworkflows\u001b[39m 0.2.0 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip  \u001b[39m 0.1.3      \u001b[32m✔\u001b[39m \u001b[34myardstick\u001b[39m 0.0.7 \n",
      "\n",
      "Warning message:\n",
      "“package ‘broom’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘dials’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘infer’ was built under R version 4.0.3”\n",
      "Warning message:\n",
      "“package ‘modeldata’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘parsnip’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘recipes’ was built under R version 4.0.1”\n",
      "Warning message:\n",
      "“package ‘tune’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘workflows’ was built under R version 4.0.2”\n",
      "Warning message:\n",
      "“package ‘yardstick’ was built under R version 4.0.2”\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Method & Results***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our project, we are using classification model to predict the type of the stars (`Type`) based on two predictors: Temperature(K) (`Temperature`) and Absolute Magnitude (`A_M`). In our dataset, the type of stars is represented by 0, 1, 2, 3, 4, 5, where 0 = Red Dwarf, 1 = Brown Dwarf, 2 = White Dwarf, 3 = Main Sequence, 4 = Super Giants, 5 = Hyper Giants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to load data from the original source on the web using `read_csv` function, and we name the dataset `Stars`. We can have a look of our dataset using `head` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsed with column specification:\n",
      "cols(\n",
      "  Temperature = \u001b[32mcol_double()\u001b[39m,\n",
      "  L = \u001b[32mcol_double()\u001b[39m,\n",
      "  R = \u001b[32mcol_double()\u001b[39m,\n",
      "  A_M = \u001b[32mcol_double()\u001b[39m,\n",
      "  Color = \u001b[31mcol_character()\u001b[39m,\n",
      "  Spectral_Class = \u001b[31mcol_character()\u001b[39m,\n",
      "  Type = \u001b[32mcol_double()\u001b[39m\n",
      ")\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Temperature</th><th scope=col>L</th><th scope=col>R</th><th scope=col>A_M</th><th scope=col>Color</th><th scope=col>Spectral_Class</th><th scope=col>Type</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>3068</td><td>0.002400</td><td>0.1700</td><td>16.12</td><td>Red</td><td>M</td><td>0</td></tr>\n",
       "\t<tr><td>3042</td><td>0.000500</td><td>0.1542</td><td>16.60</td><td>Red</td><td>M</td><td>0</td></tr>\n",
       "\t<tr><td>2600</td><td>0.000300</td><td>0.1020</td><td>18.70</td><td>Red</td><td>M</td><td>0</td></tr>\n",
       "\t<tr><td>2800</td><td>0.000200</td><td>0.1600</td><td>16.65</td><td>Red</td><td>M</td><td>0</td></tr>\n",
       "\t<tr><td>1939</td><td>0.000138</td><td>0.1030</td><td>20.06</td><td>Red</td><td>M</td><td>0</td></tr>\n",
       "\t<tr><td>2840</td><td>0.000650</td><td>0.1100</td><td>16.98</td><td>Red</td><td>M</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 7\n",
       "\\begin{tabular}{lllllll}\n",
       " Temperature & L & R & A\\_M & Color & Spectral\\_Class & Type\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <chr> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 3068 & 0.002400 & 0.1700 & 16.12 & Red & M & 0\\\\\n",
       "\t 3042 & 0.000500 & 0.1542 & 16.60 & Red & M & 0\\\\\n",
       "\t 2600 & 0.000300 & 0.1020 & 18.70 & Red & M & 0\\\\\n",
       "\t 2800 & 0.000200 & 0.1600 & 16.65 & Red & M & 0\\\\\n",
       "\t 1939 & 0.000138 & 0.1030 & 20.06 & Red & M & 0\\\\\n",
       "\t 2840 & 0.000650 & 0.1100 & 16.98 & Red & M & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 7\n",
       "\n",
       "| Temperature &lt;dbl&gt; | L &lt;dbl&gt; | R &lt;dbl&gt; | A_M &lt;dbl&gt; | Color &lt;chr&gt; | Spectral_Class &lt;chr&gt; | Type &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|\n",
       "| 3068 | 0.002400 | 0.1700 | 16.12 | Red | M | 0 |\n",
       "| 3042 | 0.000500 | 0.1542 | 16.60 | Red | M | 0 |\n",
       "| 2600 | 0.000300 | 0.1020 | 18.70 | Red | M | 0 |\n",
       "| 2800 | 0.000200 | 0.1600 | 16.65 | Red | M | 0 |\n",
       "| 1939 | 0.000138 | 0.1030 | 20.06 | Red | M | 0 |\n",
       "| 2840 | 0.000650 | 0.1100 | 16.98 | Red | M | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  Temperature L        R      A_M   Color Spectral_Class Type\n",
       "1 3068        0.002400 0.1700 16.12 Red   M              0   \n",
       "2 3042        0.000500 0.1542 16.60 Red   M              0   \n",
       "3 2600        0.000300 0.1020 18.70 Red   M              0   \n",
       "4 2800        0.000200 0.1600 16.65 Red   M              0   \n",
       "5 1939        0.000138 0.1030 20.06 Red   M              0   \n",
       "6 2840        0.000650 0.1100 16.98 Red   M              0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Stars <- read_csv(\"https://raw.githubusercontent.com/yclllll/stars-set/main/Stars.csv\")\n",
    "head(Stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, we have seven columns in the dataset, but we only need three of them, which are `Temperature`, `A_M`, and `Type`. Thus, we need to wrangle and clean the data from it's original (downloaded) format to the format necessary for the planned analysis. To clean our data, we will use `select` function to choose the columns we need and make the data into a new data called `stars`, and then we will convert `Type` from double to factor using `as_factor` function since `Type` is the target that we will predict in this project. We can have a look of our new data using `head` function again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 6 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Temperature</th><th scope=col>A_M</th><th scope=col>Type</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>3068</td><td>16.12</td><td>0</td></tr>\n",
       "\t<tr><td>3042</td><td>16.60</td><td>0</td></tr>\n",
       "\t<tr><td>2600</td><td>18.70</td><td>0</td></tr>\n",
       "\t<tr><td>2800</td><td>16.65</td><td>0</td></tr>\n",
       "\t<tr><td>1939</td><td>20.06</td><td>0</td></tr>\n",
       "\t<tr><td>2840</td><td>16.98</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 3\n",
       "\\begin{tabular}{lll}\n",
       " Temperature & A\\_M & Type\\\\\n",
       " <dbl> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t 3068 & 16.12 & 0\\\\\n",
       "\t 3042 & 16.60 & 0\\\\\n",
       "\t 2600 & 18.70 & 0\\\\\n",
       "\t 2800 & 16.65 & 0\\\\\n",
       "\t 1939 & 20.06 & 0\\\\\n",
       "\t 2840 & 16.98 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 3\n",
       "\n",
       "| Temperature &lt;dbl&gt; | A_M &lt;dbl&gt; | Type &lt;fct&gt; |\n",
       "|---|---|---|\n",
       "| 3068 | 16.12 | 0 |\n",
       "| 3042 | 16.60 | 0 |\n",
       "| 2600 | 18.70 | 0 |\n",
       "| 2800 | 16.65 | 0 |\n",
       "| 1939 | 20.06 | 0 |\n",
       "| 2840 | 16.98 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "  Temperature A_M   Type\n",
       "1 3068        16.12 0   \n",
       "2 3042        16.60 0   \n",
       "3 2600        18.70 0   \n",
       "4 2800        16.65 0   \n",
       "5 1939        20.06 0   \n",
       "6 2840        16.98 0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stars <- Stars %>%\n",
    "select(Temperature, A_M, Type) %>%\n",
    "mutate(Type = as_factor(Type))\n",
    "\n",
    "head(stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize our new data by using the `summary()` function to find the statistics for each column. We named the summary of data `star_summary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  Temperature         A_M          Type  \n",
       " Min.   : 1939   Min.   :-11.920   0:40  \n",
       " 1st Qu.: 3344   1st Qu.: -6.232   1:40  \n",
       " Median : 5776   Median :  8.313   2:40  \n",
       " Mean   :10497   Mean   :  4.382   3:40  \n",
       " 3rd Qu.:15056   3rd Qu.: 13.697   4:40  \n",
       " Max.   :40000   Max.   : 20.060   5:40  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "star_summary <- summary(stars)\n",
    "star_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will visualize our data `stars` by a scatter plot. We call this plot `star_plot`. We use `ggplot` and `geom_point` to make a scatter plot, and we use `xlab` and `ylab` to label the x-axis and y-axis. We can also label the legend use `labs` function. `ggtitle` gives a title to the plot. `options` function is used to decide the size of the plot and `theme` function is used to determine the font size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 8)\n",
    "\n",
    "star_plot <- stars %>%\n",
    "ggplot(aes(x = Temperature, y = A_M, color = Type)) +\n",
    "geom_point(alpha = 0.4) +\n",
    "xlab(\"Temperature(K)\") +\n",
    "ylab(\"Absolute Magnitude\")+\n",
    "labs(color = \"Type of Stars\") +\n",
    "theme(text = element_text(size = 20)) \n",
    "\n",
    "star_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we will start analyzing the data using classification model. First, we split `stars` data into training data and testing data using `initial_split` function. We want to use 75% of the data as training data, and we use `prop` to set this. For the `strata` argument, we place the variable we want to classify, `Type`. We call the training set `star_training` and the testing set `star_testing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_split <- initial_split(stars, prop = 0.75, strata = Type)\n",
    "star_training <- training(star_split)\n",
    "star_testing <- testing(star_split)\n",
    "\n",
    "head(star_training)\n",
    "head(star_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create the recipe using `recipe` function and `stars_training` data. We also need to standardize our training data since K-nearest neighbors is sensitive to the scale of the predictors. We first pass the target variable `Type` and predictors `Temperature` and `A_M` to the `recipe` function. To scale the predictors, we use `step_scale(all_predictors())` function; to center the predictors, we use `step_center(all_predictors())` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_recipe <- recipe(Type ~ Temperature + A_M, data = star_training) %>%\n",
    "step_scale(all_predictors()) %>%\n",
    "step_center(all_predictors())\n",
    "\n",
    "star_recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, we have split the training and testing datasets as well as preprocessed the data. Then, we will pick the best number of neighbors *K* to build the model. We want to use 5-fold-cross-validation to get a better estimate of accuracy, which will lead to a better choice of the number of neighbours *K* for the overall set of training data. In 5-fold-cross-validation, we split our overall training data into 5 evenly-sized chunks, and then iteratively use 1 chunk as the validation set and combine the remaining 5−1 chunks as the training set. To perform this, we use `vfold_cv` function. In the function, we identify the training set `stars_training`, the number of folds `v` = 5, and the `strata` argument is `Type`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_vfold <- vfold_cv(star_training, v = 5, strata = Type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a 5-fold cross-validation, we have established a prediction accuracy for our classifier. Then we want to create a *K*-nearest neighbor model specification. In the specification, we use `tune()` to let each parameter in the model can be adjusted rather than given a specific value. We call the model specification `star_spec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) %>%\n",
    "set_engine(\"kknn\") %>%\n",
    "set_mode(\"classification\")\n",
    "\n",
    "star_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create a `workflow()` analysis that combines `star_recipe` and `star_spec` model specification. In the workflow, we will use `tune_grid` function to fit the model for each value in a range of parameter values. For the `resamples` argument, input the `star_vfold` model we created earlier. The `grid` argument specifies that the tuning should try *X* amount of values of the number of neighbors *K* when tuning. In this project, we use number of neighbors from 1 to 50. Finally, we use `collect_metrics()` to  aggregate the mean and standard error. We call this workflow analysis `star_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridvals <- tibble(neighbors = seq(from = 1, to = 50))\n",
    "\n",
    "star_results <- workflow() %>%\n",
    "add_recipe(star_recipe) %>%\n",
    "add_model(star_spec) %>%\n",
    "tune_grid(resamples = star_vfold, grid = gridvals) %>%\n",
    "collect_metrics()\n",
    "\n",
    "head(star_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can find the best value of the number of neighbors based on `star_results`. We first filter for `accuracy` from the `.metric` column, we call the dataset `accuracies`. Then, we create a line plot using the `accuracies` dataset with `neighbors` on the x-axis and the `mean` on the y-axis. We call the plot `accuracy_vs_k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies <- star_results %>%\n",
    "filter(.metric == \"accuracy\")\n",
    "\n",
    "accuracy_vs_k <- accuracies %>% \n",
    "ggplot(aes(x = neighbors, y = mean)) +\n",
    "geom_point() +\n",
    "geom_line() +\n",
    "labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "theme(text = element_text(size = 20))\n",
    "\n",
    "accuracy_vs_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from the above plot that *K* = 1, 2 provides the highest accuracy. Therefore, we choose *K* = 2 as the best value of number of neighbors. Now, we will create a new model specification with *K* = 2, we call this new model specification `star_best_spec`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_best_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 2) %>%\n",
    "set_engine(\"kknn\") %>%\n",
    "set_mode(\"classification\")\n",
    "\n",
    "star_best_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we train the classifier with the training data `star_training` set using the `workflow` function, so we can bundle together the pre-processing, modeling, and post-processing requests. We name the workflow `star_fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_fit <- workflow() %>%\n",
    "add_recipe(star_recipe) %>%\n",
    "add_model(star_best_spec) %>%\n",
    "fit(data = star_training)\n",
    "\n",
    "star_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to predict the class labels for our testing set. We pass the fitted model and the test dataset `star_testing` to the `predict` function. Then, we use the `bind_cols` function to add the column of predictions to the original test data. We call the predictions `star_predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_predictions <- predict(star_fit, star_testing) %>%\n",
    "bind_cols(star_testing)\n",
    "\n",
    "head(star_predictions)\n",
    "tail(star_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to see our classifier's accuracy. So we use `metrics` function to help us. We input `Type` as the `truth` argument, and `.pred_class` as the `estimate` argument, then we `filter` the `accuracy` row to see the accuracy of our classifier. We call this object `star_test_predictions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_test_predictions <- star_predictions %>%\n",
    "metrics(truth = Type, estimate = .pred_class) %>%\n",
    "filter(.metric == \"accuracy\")\n",
    "\n",
    "star_test_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our classifier's accuracy is about 96.67%. We also want to look at the confusion matrix for the classifier, which shows us the table of predicted labels and correct labels. We perform this using `conf_mat` function, we need to specify the `truth` and `estimate` argument as we did in `metrics` function. We call this confusion matrix `star_mat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "star_mat <- star_predictions %>%\n",
    "conf_mat(truth = Type, estimate = .pred_class)\n",
    "\n",
    "star_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "As shown in the Methods and Results section, we used the k-nearest neighbor method and created a classification model to determine the star types of our testing data. As the result, the prediction accuracy for the testing data frame is about 96.67% based on our classifier. Then, the confusion matrix is generated to see details of our prediction. We expected the accuracy of the classifier to be larger than 80% when predicting the testing data frame. 96.67% satisfies and exceeds our expectations. As a result, our classifier is good for determining an unknown star’s type with a very high accuracy. Based on our project and its results, a future question could be: is it better if we use other variables (except temperature and absolute magnitude) to predict the star type to achieve better accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
